{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns found: Index(['state', 'lastcheckuptime', 'physicalactivities', 'removedteeth',\n",
      "       'hadangina', 'hadstroke', 'hadasthma', 'hadskincancer', 'hadcopd',\n",
      "       'haddepressivedisorder', 'hadkidneydisease', 'hadarthritis',\n",
      "       'haddiabetes', 'deaforhardofhearing', 'blindorvisiondifficulty',\n",
      "       'difficultyconcentrating', 'difficultywalking',\n",
      "       'difficultydressingbathing', 'difficultyerrands', 'smokerstatus',\n",
      "       'ecigaretteusage', 'chestscan', 'raceethnicitycategory', 'agecategory',\n",
      "       'alcoholdrinkers', 'hivtesting', 'fluvaxlast12', 'pneumovaxever',\n",
      "       'tetanuslast10tdap', 'highrisklastyear', 'covidpos', 'bmicategory'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "data = pd.read_csv('/Users/jeevaharidas/Desktop/cleaned_standardized_heart_data.csv')  # Update the path as needed\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "# Fill numerical columns with their median\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "data[numerical_cols] = data[numerical_cols].fillna(data[numerical_cols].median())\n",
    "\n",
    "# Fill categorical columns with their mode\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"Categorical columns found: {categorical_cols}\")\n",
    "    data[categorical_cols] = data[categorical_cols].fillna(data[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Step 3: Encode categorical variables\n",
    "# Map binary columns to 1/0\n",
    "binary_columns = [\n",
    "    'hadheartattack', 'hadangina', 'hadstroke', 'hadasthma', 'hadskincancer',\n",
    "    'hadcopd', 'haddepressivedisorder', 'hadkidneydisease', 'hadarthritis',\n",
    "    'haddiabetes', 'deaforhardofhearing', 'blindorvisiondifficulty',\n",
    "    'difficultyconcentrating', 'difficultywalking', 'difficultydressingbathing',\n",
    "    'difficultyerrands', 'highrisklastyear', 'covidpos'\n",
    "]\n",
    "for col in binary_columns:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Perform one-hot encoding for remaining categorical variables\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: Index(['generalhealth', 'physicalhealthdays', 'mentalhealthdays', 'sleephours',\n",
      "       'hadheartattack', 'hadangina', 'hadstroke', 'hadasthma',\n",
      "       'hadskincancer', 'hadcopd',\n",
      "       ...\n",
      "       'agecategory_Age 70 to 74', 'agecategory_Age 75 to 79',\n",
      "       'agecategory_Age 80 or older', 'alcoholdrinkers_Yes', 'hivtesting_Yes',\n",
      "       'fluvaxlast12_Yes', 'pneumovaxever_Yes',\n",
      "       'tetanuslast10tdap_Yes, received Tdap',\n",
      "       'tetanuslast10tdap_Yes, received tetanus shot but not sure what type',\n",
      "       'tetanuslast10tdap_Yes, received tetanus shot, but not Tdap'],\n",
      "      dtype='object', length=116)\n",
      "Preview of the dataset:\n",
      "   generalhealth  physicalhealthdays  mentalhealthdays  sleephours  \\\n",
      "0              4            0.000000          0.000000    0.468668   \n",
      "1              0            0.000000          0.000000   -0.531332   \n",
      "2              4            0.792481          0.773706   -1.144710   \n",
      "3              0            0.000000          0.000000    0.000000   \n",
      "4              1            0.792481          0.000000    0.887906   \n",
      "\n",
      "   hadheartattack  hadangina  hadstroke  hadasthma  hadskincancer  hadcopd  \\\n",
      "0             NaN          0          0          0              0        0   \n",
      "1             NaN          0          0          0              1        0   \n",
      "2             NaN          0          0          0              1        0   \n",
      "3             NaN          0          0          1              0        0   \n",
      "4             NaN          0          0          0              0        0   \n",
      "\n",
      "   ...  agecategory_Age 70 to 74  agecategory_Age 75 to 79  \\\n",
      "0  ...                     False                     False   \n",
      "1  ...                     False                     False   \n",
      "2  ...                     False                     False   \n",
      "3  ...                     False                     False   \n",
      "4  ...                     False                     False   \n",
      "\n",
      "   agecategory_Age 80 or older  alcoholdrinkers_Yes  hivtesting_Yes  \\\n",
      "0                         True                False           False   \n",
      "1                         True                False           False   \n",
      "2                        False                False           False   \n",
      "3                        False                False           False   \n",
      "4                        False                 True           False   \n",
      "\n",
      "   fluvaxlast12_Yes  pneumovaxever_Yes  tetanuslast10tdap_Yes, received Tdap  \\\n",
      "0              True              False                                 False   \n",
      "1             False              False                                 False   \n",
      "2             False              False                                 False   \n",
      "3              True               True                                 False   \n",
      "4             False               True                                 False   \n",
      "\n",
      "   tetanuslast10tdap_Yes, received tetanus shot but not sure what type  \\\n",
      "0                                               True                     \n",
      "1                                              False                     \n",
      "2                                              False                     \n",
      "3                                              False                     \n",
      "4                                              False                     \n",
      "\n",
      "   tetanuslast10tdap_Yes, received tetanus shot, but not Tdap  \n",
      "0                                              False           \n",
      "1                                              False           \n",
      "2                                              False           \n",
      "3                                              False           \n",
      "4                                              False           \n",
      "\n",
      "[5 rows x 116 columns]\n",
      "Preview of 'hadheartattack':\n",
      "0   NaN\n",
      "1   NaN\n",
      "2   NaN\n",
      "3   NaN\n",
      "4   NaN\n",
      "Name: hadheartattack, dtype: float64\n",
      "Unique values in 'hadheartattack': [nan]\n",
      "Missing values in 'hadheartattack': 445132\n"
     ]
    }
   ],
   "source": [
    "# Inspect the dataset\n",
    "print(\"Columns in the dataset:\", data.columns)\n",
    "print(\"Preview of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check if 'hadheartattack' exists in the original dataset\n",
    "if 'hadheartattack' not in data.columns:\n",
    "    print(\"'hadheartattack' column is missing in the dataset.\")\n",
    "else:\n",
    "    print(\"Preview of 'hadheartattack':\")\n",
    "    print(data['hadheartattack'].head())\n",
    "    print(\"Unique values in 'hadheartattack':\", data['hadheartattack'].unique())\n",
    "    print(\"Missing values in 'hadheartattack':\", data['hadheartattack'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding a placeholder 'hadheartattack' column for testing...\n",
      "Placeholder 'hadheartattack' column added.\n"
     ]
    }
   ],
   "source": [
    "# Add a placeholder target column\n",
    "print(\"Adding a placeholder 'hadheartattack' column for testing...\")\n",
    "data['hadheartattack'] = np.random.choice([0, 1], size=len(data), p=[0.8, 0.2])\n",
    "print(\"Placeholder 'hadheartattack' column added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values filled with mode: 0\n"
     ]
    }
   ],
   "source": [
    "mode_value = data['hadheartattack'].mode()\n",
    "if not mode_value.empty:\n",
    "    data['hadheartattack'] = data['hadheartattack'].fillna(mode_value[0])\n",
    "    print(\"Missing values filled with mode:\", mode_value[0])\n",
    "else:\n",
    "    raise ValueError(\"Unable to fill missing values in 'hadheartattack'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of 'hadheartattack': 0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: hadheartattack, dtype: int64\n",
      "Unique values in 'hadheartattack': [1 0]\n",
      "Missing values in 'hadheartattack': 0\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Define features (X) and target (y)\n",
    "# Check if the target column exists\n",
    "if 'hadheartattack' not in data.columns:\n",
    "    print(\"'hadheartattack' column is missing. Adding a placeholder column for testing...\")\n",
    "    data['hadheartattack'] = np.random.choice([0, 1], size=len(data), p=[0.8, 0.2])\n",
    "    print(\"Placeholder 'hadheartattack' column added.\")\n",
    "\n",
    "# Debug and inspect the target column\n",
    "print(\"Preview of 'hadheartattack':\", data['hadheartattack'].head())\n",
    "print(\"Unique values in 'hadheartattack':\", data['hadheartattack'].unique())\n",
    "print(\"Missing values in 'hadheartattack':\", data['hadheartattack'].isnull().sum())\n",
    "\n",
    "# Handle missing or invalid target values\n",
    "if data['hadheartattack'].isnull().sum() > 0:\n",
    "    print(\"Missing values detected. Attempting to handle...\")\n",
    "    mode_value = data['hadheartattack'].mode()\n",
    "    if not mode_value.empty:\n",
    "        data['hadheartattack'] = data['hadheartattack'].fillna(mode_value[0])\n",
    "        print(\"Missing values filled with mode:\", mode_value[0])\n",
    "    else:\n",
    "        print(\"Column is completely empty. Adding placeholder target values for testing...\")\n",
    "        data['hadheartattack'] = np.random.choice([0, 1], size=len(data), p=[0.8, 0.2])\n",
    "        print(\"Placeholder 'hadheartattack' column added.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the target column exists and handle missing values\n",
    "if 'hadheartattack' not in data.columns:\n",
    "    print(\"'hadheartattack' column is missing. Adding a placeholder column for testing...\")\n",
    "    data['hadheartattack'] = np.random.choice([0, 1], size=len(data), p=[0.8, 0.2])\n",
    "    print(\"Placeholder 'hadheartattack' column added.\")\n",
    "elif data['hadheartattack'].isnull().sum() == len(data):\n",
    "    print(\"Target column is completely empty. Adding placeholder values for testing...\")\n",
    "    data['hadheartattack'] = np.random.choice([0, 1], size=len(data), p=[0.8, 0.2])\n",
    "    print(\"Placeholder 'hadheartattack' column added.\")\n",
    "elif data['hadheartattack'].isnull().sum() > 0:\n",
    "    print(\"Missing values in 'hadheartattack' detected. Attempting to handle...\")\n",
    "    mode_value = data['hadheartattack'].mode()\n",
    "    if not mode_value.empty:\n",
    "        data['hadheartattack'] = data['hadheartattack'].fillna(mode_value[0])\n",
    "        print(\"Missing values filled with mode:\", mode_value[0])\n",
    "    else:\n",
    "        raise ValueError(\"Unable to fill missing values in 'hadheartattack'. Verify the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of 'hadheartattack':\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: hadheartattack, dtype: int64\n",
      "Unique values in 'hadheartattack': [1 0]\n",
      "Missing values in 'hadheartattack': 0\n"
     ]
    }
   ],
   "source": [
    "# Debug and inspect the target column\n",
    "print(\"Preview of 'hadheartattack':\")\n",
    "print(data['hadheartattack'].head())\n",
    "print(\"Unique values in 'hadheartattack':\", data['hadheartattack'].unique())\n",
    "print(\"Missing values in 'hadheartattack':\", data['hadheartattack'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing values in features with median...\n",
      "Missing values filled in features.\n",
      "Data preprocessing and balancing complete.\n",
      "X_train_smote shape: (569523, 115)\n",
      "y_train_smote shape: (569523,)\n"
     ]
    }
   ],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data.drop('hadheartattack', axis=1)\n",
    "y = data['hadheartattack']\n",
    "\n",
    "# Step 1: Handle missing values in target\n",
    "if y.isnull().sum() > 0:\n",
    "    print(\"Filling missing values in the target variable with mode...\")\n",
    "    y = y.fillna(y.mode()[0])\n",
    "    print(\"Missing values filled in target variable.\")\n",
    "\n",
    "# Step 2: Handle missing values in features\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(\"Filling missing values in features with median...\")\n",
    "    X = X.fillna(X.median())\n",
    "    print(\"Missing values filled in features.\")\n",
    "\n",
    "# Step 3: Apply SMOTE for class balancing\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Step 4: Split into training and testing sets\n",
    "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Confirm successful preprocessing\n",
    "print(\"Data preprocessing and balancing complete.\")\n",
    "print(f\"X_train_smote shape: {X_train_smote.shape}\")\n",
    "print(f\"y_train_smote shape: {y_train_smote.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean columns found: Index(['sex_male', 'state_Alaska', 'state_Arizona', 'state_Arkansas',\n",
      "       'state_California', 'state_Colorado', 'state_Connecticut',\n",
      "       'state_Delaware', 'state_District of Columbia', 'state_Florida',\n",
      "       'state_Georgia', 'state_Guam', 'state_Hawaii', 'state_Idaho',\n",
      "       'state_Illinois', 'state_Indiana', 'state_Iowa', 'state_Kansas',\n",
      "       'state_Kentucky', 'state_Louisiana', 'state_Maine', 'state_Maryland',\n",
      "       'state_Massachusetts', 'state_Michigan', 'state_Minnesota',\n",
      "       'state_Mississippi', 'state_Missouri', 'state_Montana',\n",
      "       'state_Nebraska', 'state_Nevada', 'state_New Hampshire',\n",
      "       'state_New Jersey', 'state_New Mexico', 'state_New York',\n",
      "       'state_North Carolina', 'state_North Dakota', 'state_Ohio',\n",
      "       'state_Oklahoma', 'state_Oregon', 'state_Pennsylvania',\n",
      "       'state_Puerto Rico', 'state_Rhode Island', 'state_South Carolina',\n",
      "       'state_South Dakota', 'state_Tennessee', 'state_Texas', 'state_Utah',\n",
      "       'state_Vermont', 'state_Virgin Islands', 'state_Virginia',\n",
      "       'state_Washington', 'state_West Virginia', 'state_Wisconsin',\n",
      "       'state_Wyoming',\n",
      "       'lastcheckuptime_Within past 2 years (1 year but less than 2 years ago)',\n",
      "       'lastcheckuptime_Within past 5 years (2 years but less than 5 years ago)',\n",
      "       'lastcheckuptime_Within past year (anytime less than 12 months ago)',\n",
      "       'physicalactivities_Yes', 'removedteeth_6 or more, but not all',\n",
      "       'removedteeth_All', 'removedteeth_None of them',\n",
      "       'smokerstatus_Current smoker - now smokes some days',\n",
      "       'smokerstatus_Former smoker', 'smokerstatus_Never smoked',\n",
      "       'ecigaretteusage_Not at all (right now)',\n",
      "       'ecigaretteusage_Use them every day',\n",
      "       'ecigaretteusage_Use them some days', 'chestscan_Yes',\n",
      "       'raceethnicitycategory_Hispanic',\n",
      "       'raceethnicitycategory_Multiracial, Non-Hispanic',\n",
      "       'raceethnicitycategory_Other race only, Non-Hispanic',\n",
      "       'raceethnicitycategory_White only, Non-Hispanic',\n",
      "       'agecategory_Age 25 to 29', 'agecategory_Age 30 to 34',\n",
      "       'agecategory_Age 35 to 39', 'agecategory_Age 40 to 44',\n",
      "       'agecategory_Age 45 to 49', 'agecategory_Age 50 to 54',\n",
      "       'agecategory_Age 55 to 59', 'agecategory_Age 60 to 64',\n",
      "       'agecategory_Age 65 to 69', 'agecategory_Age 70 to 74',\n",
      "       'agecategory_Age 75 to 79', 'agecategory_Age 80 or older',\n",
      "       'alcoholdrinkers_Yes', 'hivtesting_Yes', 'fluvaxlast12_Yes',\n",
      "       'pneumovaxever_Yes', 'tetanuslast10tdap_Yes, received Tdap',\n",
      "       'tetanuslast10tdap_Yes, received tetanus shot but not sure what type',\n",
      "       'tetanuslast10tdap_Yes, received tetanus shot, but not Tdap'],\n",
      "      dtype='object')\n",
      "Categorical columns found: Index([], dtype='object')\n",
      "No categorical columns found for imputation.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Identify boolean columns\n",
    "bool_cols = X_sample.select_dtypes(include=['bool']).columns\n",
    "print(\"Boolean columns found:\", bool_cols)\n",
    "\n",
    "# Convert boolean columns to integers (1 for True, 0 for False)\n",
    "X_sample[bool_cols] = X_sample[bool_cols].astype(int)\n",
    "\n",
    "# Impute missing values for numerical columns with the median\n",
    "numerical_cols = X_sample.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "X_sample[numerical_cols] = num_imputer.fit_transform(X_sample[numerical_cols])\n",
    "\n",
    "# Identify categorical columns (exclude numerical columns and already processed boolean columns)\n",
    "categorical_cols = X_sample.select_dtypes(exclude=['number']).columns\n",
    "print(\"Categorical columns found:\", categorical_cols)\n",
    "\n",
    "# Impute missing values for categorical columns with the mode\n",
    "if len(categorical_cols) > 0:\n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X_sample[categorical_cols] = cat_imputer.fit_transform(X_sample[categorical_cols])\n",
    "else:\n",
    "    print(\"No categorical columns found for imputation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns found: Index([], dtype='object')\n",
      "No categorical columns found for imputation.\n",
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.0s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=  14.4s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=  15.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  25.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  25.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  26.1s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=  14.0s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=  14.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=  18.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=  18.1s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.6s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.9s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   9.3s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   8.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  11.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   8.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=150; total time=   9.1s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  17.3s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  17.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=  16.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=150; total time=  17.7s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   8.8s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   9.1s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=150; total time=  13.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  11.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   6.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=150; total time=   6.7s\n",
      "Best Parameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 20, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Debug categorical columns\n",
    "categorical_cols = X_sample.select_dtypes(exclude=['number']).columns\n",
    "print(\"Categorical columns found:\", categorical_cols)\n",
    "\n",
    "# Impute numerical columns with median\n",
    "numerical_cols = X_sample.select_dtypes(include=['float64', 'int64']).columns\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "X_sample[numerical_cols] = num_imputer.fit_transform(X_sample[numerical_cols])\n",
    "\n",
    "# Impute categorical columns with mode, if they exist\n",
    "if len(categorical_cols) > 0:\n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    X_sample[categorical_cols] = cat_imputer.fit_transform(X_sample[categorical_cols])\n",
    "else:\n",
    "    print(\"No categorical columns found for imputation.\")\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV for tuning\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid_rf,\n",
    "    n_iter=20,\n",
    "    scoring='roc_auc',\n",
    "    cv=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "rf_search.fit(X_sample, y_sample)\n",
    "\n",
    "# Output the best parameters\n",
    "print(\"Best Parameters:\", rf_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
